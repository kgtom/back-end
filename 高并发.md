## 学习大纲
- [一、高并发是什么？](#1)
- [二、高并发重要参数](#2)
- [三、如何提高高并发](#3)
- [四、典型场景案例分析](#4)


## <span id="1">一、高并发是什么？</span>
 **并发：**
 操作系统并发指 cpu同时处理多件任务，互联网高并发多指某个时间点有多少个访问同时到来，通常指日PV量。
 
## <span id="2">二、高并发参数</span>
**QPS：** 每秒钟请求或者查询的数量，在互联网领域，指每秒响应请求数(指HTTP请求)

**吞吐量：** 单位时间内处理的请求数量(通常由QPS与并发数决定)

**响应时间：** 从请求发出到收到响应花费的时间，例如系统处理一个HTTP请求需要100ms，这个100ms就是系统的响应时间

**PV：** 综合浏览量(Page View)，即页面浏览量或者点击量，一个访客在24小时内访问的页面数量，同一个人浏览你的网站同一页面，只记作一次PV

**UV：** 独立访问(UniQue Visitor)，即一定时间范围内相同访客多次访问网站，只计算为1个独立访客

**带宽：** 计算带宽大小需关注两个指标，峰值流量和页面的平均大小 

日网站带宽=PV/统计时间(换算到秒)*平均页面大小(单位KB)*8

峰值一般是平均值的倍数，根据实际情况来定

QPS不等于并发连接数

QPS是每秒HTTP请求数量，并发连接数是系统同时处理的请求数量

(总PV数*80%)/(6小时秒数*20%)=峰值每秒请求数(QPS)

80%的访问量集中在20%的时间！！！
 

  随着QPS的增长，每个阶段需要根据实际情况来进行优化，优化的方案也与硬件条件、网络带宽息息相关。


| qps数量 |网站类型|面临问题及解决| 
| - | - | -|
| 50 | 小型网站 |对服务器没有大挑战 | 
| 100 | 中型网站 |假设关系型数据库的每次请求在0.01秒完成，假设单页面只有一个SQL查询，那么100QPS意味这1秒钟完成100次请求，但是此时我们并不能保证数据库查询能完成100次。方案：数据库缓存层、数据库的负载均衡 | 
|800 | 大型网站|假设我们使用百兆带宽，意味着网站出口的实际带宽是8M左右,假设每个页面只有10k,在这个并发条件下，百兆带宽已经吃完.方案：CDN加速、负载均衡|
|1000 | 超大型 |假设使用Memcache缓存数据库查询数据，每个页面对Memcache的请求远大于直接对DB的请求,Memcache的悲观并发数在2W左右，但有可能在之前内网带宽已经吃光，表现出不稳定。方案：静态HTML缓存|
|2000 | 特大 |这个级别下，文件系统访问锁都成为灾难。方案：做业务分离，分布式存储|


**ps:**
 100M带宽，一个页面100k，假设每秒种能提供 10MB 的数据量，那么 10MB ÷ 100KB = 100 个页面，意味着 百兆宽带qps 最大100.

## <span id="3">三、如何提高高并发</span>
### 1.增加服务器--->针对小型网站
 * 简单、粗暴，效果明显。
### 2、缓存--->缓解高并发下对db i/o开销
* http缓存:页面级浏览器缓存、Nginx代理层缓存、HttpClient缓存库的CacheConfig

* 应用程序缓存

    **首次：**用户请求-->数据查询-->连接数据库服务器并查询数据-->将数据缓存起来(HTML、内存、JSON、序列化数据)-->显示给客户端

    **之后：**用户再次请求或者新用户访问-->数据查询-->直接从缓存中获取数据-->显示给客户端
* 分布式缓存：
  * 产生背景：由于单台机器的内存资源以及承载能力有限，并且，如果大量使用本地缓存，也会使相同的数据被不同的节点存储多份，对内存资源造成较大的浪费，因此，才催生出了分布式缓存。
  * 使用过程：数据库读写分离(M/S)–>数据库使用多个Slave–>增加Cache (memcache)–>转到Redis
    由memcache 转到redis 因为后者有5种数据结构。
### 3.CND加速--->减少影响数据传输的速度和稳定性
 * 跨运营商的网络加速，保证不同网络的用户都得到良好的访问质量

 * 远程访问用户根据DNS负载均衡技术智能自动选择Cache服务器

### 4.反向代理、负载均衡--->Nginx、集群
  配置简单、功能强大
  
#### 5.消息队列nsq---->异步、消峰
   * 异步：将请求先放在nsq或者redis中，然后再获取有效请求执行
   * 消峰:并发量大的时候，不直接访问db
   
## <span id="4">四、典型场景案例分析</span>
**特价机票秒杀场景**
### 1.流程
      前端下单、后台扣减库存
### 2.需要考虑点
   - 瞬间访问量激增---->消峰(nsq)
   - 请求数量>库存数量 ----->异步(nsq)+缓存(读写缓存，然后再同步到db)
   
### 3.前后端需要做的事情

  #### 前端:

1. 页面静态化：将活动页面上的所有可以静态的元素全部静态化，并尽量减少动态元素。通过CDN来抗峰值。 
2. 禁止重复提交：用户点击【下单】按钮之后，按钮置灰，js 禁止重复提交 
3. 用户限流：在某一时间段内只允许用户提交一次请求，比如可以使用Nginx对IP限流(漏桶原理)，如同安检，每次只能进入3人，多了排队，然后依次进入。

#### 后端:

##### 1.网关层
限制 登录用户 UserId 访问频率：我们上面拦截了浏览器访问的请求，但针对某些恶意攻击或其它插件，在服务端控制层需要针对同一个访问 UserId，限制访问频率,使用redis中incr命令。

##### 2.服务层
上面只拦截了一部分访问请求，当秒杀的用户量很大时，即使每个用户只有一个请求，到服务层的请求数量还是很大。比如我们有100W用户同时抢100张北京飞洛杉矶商务舱机票，服务层并发请求压力至少为100W。

* 采用消息队列nsq 或者redis 缓存请求：既然服务层知道库存只有100张机票，那完全没有必要把100W个请求都传递到数据库啊，那么可以先把这些请求都写到消息队列nsq缓存一下，数据库层订阅消息减库存，减库存成功的请求返回秒杀成功，失败的返回秒杀结束。

* 利用缓存应对读请求：对类似于12306等购票业务，是典型的读多写少业务，大部分请求是查询请求，所以可以利用缓存分担数据库压力,从缓存中查询100张机票票数及信息。

* 利用缓存应对写请求：缓存也是可以应对写请求的，比如我们就可以把数据库中的库存数据转移到Redis缓存中，所有减库存操作都在Redis中进行，然后再通过后台进程把Redis中的用户秒杀请求同步到数据库中。
##### 3.数据库层
* 数据库层是最脆弱的一层，一般在应用设计时在上游就需要把请求拦截掉，数据库层只承担“能力范围内”的访问请求。所以，上面通过在服务层引入队列和缓存，让最底层的数据库高枕无忧。
  

## reference
* [csdn](https://blog.csdn.net/beihenanfei/article/details/78919682)
* [cnblogs](https://www.cnblogs.com/New-Zealand/p/5165663.html)
* [cnblogs](https://www.cnblogs.com/wangzhongqiu/p/6557596.html)

 
