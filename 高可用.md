## 一、前言


   系统刚搭建完成好比建造了一个**土房子**，考虑自己能在里面住就可以了，而发展到**四合院**，就要考虑东厢、西厢等一些布局的问题，再发展到一个**小区**，就涉及内部道路、配套等等，再大一点发展成一个**城市**，就要涉及要各种保障工作，比如下雨了怎么排水，进城要设置哪些关卡，哪些道路要放置监控等。


![---](https://github.com/kgtom/back-end/blob/master/pic/system-grow.png)


系统建设也是这样，一个用户基数小、日活少的系统，要考虑的主要是完成功能，随着业务量增大，就要开始涉及系统间的问题，接着去发展一些基础设施、共通组件等，而我们目前的局面是，系统已经扩大到了**城市**的规模，我们要解决更繁重的问题。


## 二、发现问题

   在很长时间里，我们做的只是在原有系统上增加功能，架构上没有大调整。但是随着业务增长，就算我们系统没有任何发版升级，也会突然出现一些事故。事故出现的频率越来越高，我们自身的升级，也经常是困难重重。基础设施升级、上下游升级，经常会发生“蝴蝶效应”，毫无征兆的受到影响。以下是这些现象的鱼骨图分析：
   
   
![---](https://github.com/kgtom/back-end/blob/master/pic/%E9%B1%BC%E9%AA%A8%E5%9B%BE.png)

  通过排查，我们发现了系统的主要问题，从大方面说就是：外部的问题和自身的问题，当然症结在于架构的问题。问题分类如下图所示：
  
![--](https://github.com/kgtom/back-end/blob/master/pic/%E9%97%AE%E9%A2%98.png)

## 三、分析问题
### 1. 事务中包含外部调用

外部调用包括对外部系统的调用和基础组件的调用，如果外部调用超时，必然造成本次事务失败。
     
### 2.超时时间和重试次数不合理 
对外部系统和缓存、消息队列等基础组件的依赖，
如果超时时间设置过长、重试过多，系统长时间不返回，可能会导致连接池被打满，系统死掉；
如果超时时间设置过短，499错误会增多，系统的可用性会降低。
如果超时时间设置得短，重试次数设置得多，会增加系统的整体耗时；
如果超时时间设置得短，重试次数设置得也少，那么这次请求的返回结果会不准确


### 3. 外部依赖的地方没有熔断(降级)的问题(即：我们依赖的地方)
系统没有熔断，如果由于代码逻辑问题上线引起故障、网络问题、调用超时、业务促销调用量激增、服务容量不足等原因，服务调用链路上有一个下游服务出现故障，就可能导致接入层其它的业务不可用。

![----1](https://github.com/kgtom/back-end/blob/master/pic/%E6%97%A0%E7%86%94%E6%96%AD.png)


### 4. 依赖我们的地方没有限流的问题
在开放式的网络环境下，对外系统往往会收到很多有意无意的恶意攻击，如DDoS攻击、用户失败重刷。
![----2](https://github.com/kgtom/back-end/blob/master/pic/%E6%97%A0%E9%99%90%E6%B5%81.png)

### 5.依赖不合理的问题
 每多一个依赖方，风险就会累加。特别是强依赖，它本身意味着一荣俱荣、一损俱损。

### 6. 没有有效的资源隔离
 容易造成级联多米诺骨牌效应。

### 7. 慢查询问题

![----3](https://github.com/kgtom/back-end/blob/master/pic/%E6%85%A2%E6%9F%A5%E8%AF%A2.png)

### 8. 废弃逻辑和临时代码
过期的代码会对正常逻辑有干扰，让代码不清晰。特别是对新加入的同事，他们对明白干什么用的代码可以处理。但是已经废弃的和临时的，因为不知道干什么用的，所以改起来更忐忑。如果知道是废弃的，其它功能改了这一块没改，也有可能这块不兼容，引发问题。

## 四、解决问题(如何实现高可用)

### 1.高可用指标
衡量一个系统的可用性有两个指标：
1. MTBF (Mean Time Between Failure) 即平均多长时间不出故障；
2. MTTR (Mean Time To Recovery) 即出故障后的平均恢复时间。

![availability](https://github.com/kgtom/back-end/blob/master/pic/availability.png)

通过这两个指标可以计算出可用性，也就是我们大家比较熟悉的“几个9”。

![availability-stander](https://github.com/kgtom/back-end/blob/master/pic/availability-stander.png)


![-------](https://github.com/kgtom/back-end/blob/master/pic/%E5%8F%AF%E7%94%A8%E6%80%A7%E8%AE%A1%E7%AE%97.png)

因此提升系统的可用性，就得从这两个指标入手，要么降低故障恢复的时间，要么延长不出故障的时间。
 
*  要降低故障恢复的时间，首先得尽早的发现故障，然后才能解决故障，这些故障包括系统内和系统外的，这就需要依赖业务监控系统。即：日志收集+搜索+显示(ELK)
* 要延长不出故障的时间，有以下方法，例如：对依赖我们的限流，我们自身要降级、回滚，我们依赖的要隔离，对于外部调用要有超时及重试机制，具体如下：

### 2.方法

#### 1. 事务中不包含外部调用

 * 排查各个系统的代码，检查在事务中是否存在RPC调用、HTTP调用、消息队列操作、缓存、循环查询等耗时的操作，这个操作应该移到事务之外，理想的情况是事务内只处理数据库操作。
 * 将大事务拆分小事务，降低db的资源被长时间事务锁占用而造成db瓶颈
 * 数据库事务异步化，基于消息服务提供异步机制。

#### 2.设置合理的超时时间和重试次数

* 设置超时时间原则：调用方的超时时间>依赖服务自己的超时时间
* 重试次数：一般3次，否则可以不重试

#### 3.外部依赖要做熔断，即：降级、回滚（**上游死，我们不死**）

在依赖的服务不可用时，服务调用方应该通过一些技术手段，向上提供有损服务，保证业务柔性可用。
 
 **举例:**
 对非关键路径上的服务故障做了降级。例如账号的一个查询服务依赖Redis，当Redis抖动的时候服务的可用性也随之降低，我们通过自研kv中间件做Redis的备用存储，当检测到Redis已经非常不可用时就切到kv中间件上。
#### 4.依赖我们地方要做限流（**不被下游弄死**）

* 通过对服务端的业务性能压测，可以分析出一个相对合理的最大QPS。
* 流量控制中用的比较多的三个算法是[令牌桶、漏桶、计数器](https://github.com/kgtom/daily-life/blob/master/important/%E5%AF%B9%E9%AB%98%E5%B9%B6%E5%8F%91%E9%99%90%E6%B5%81%E7%9A%84%E4%B8%80%E7%82%B9%E6%80%9D%E8%80%83.md)。
 **举例:**
 同一个账号 在一分钟内，不能超过20次请求。可以通过设置计数器

#### 5.依赖不合理地方 （**做到自己不死**）

**要是有依赖就去依赖，去不了，就弱依赖，如果要强依赖，那就熔断。**

a.别人死我们不死：无依赖，

熔断：别人死了，我们快速失败，安全提示，例如：第三方登录超时，提示使用其他登录方式
     别人活了，快速恢复：心跳检查 或者 事件监听
     需要设置合理超时和重试、蓄洪、限流、熔断、降级


b.自己不作死：
不作：不当小白鼠，用成熟的技术；规范研发流程、做好测试和演练
不死：单个节点挂了，用集群；单个机房挂了，用多机房；整个地区网断，用多机房；即：异地多活
涉及到集群和跨区的要有策略：负载均衡、主从切换，优先策略

例如 用户中心---账号模块具体做法：
考虑到账号读多写少的特性（，我们采用了一主多从的数据库部署方案，优先解决读多活的问题。
Redis如果也用一主多从的模式可行吗？答案是不行，因为Redis主从同步机制会优先尝试增量同步，当增量同步不成功时，再去尝试全量同步，一旦专线发生抖动就会把主库拖垮，并进一步阻塞专线，形成“雪崩效应”。因此两地的Redis只能是双主模式，但是这种架构有一个问题，就是我们得自己去解决数据同步的问题，除了保证数据不丢，还要保证数据一致。
如何保障同步呢？
1.基于nsq 消息队列
2.定时任务去scan两地的数据做对比统计，如果发现有不一致的还能及时修复掉。

总体上账号的异地多活遵循以下三个原则：
1.北上任何一地故障，另一地都可提供完整服务。
2.北上两地同时对外提供服务，确保服务随时可用。
3.两地服务都遵循BASE原则，确保数据最终一致。

c.不被队友搞死：
队友：部门内部依赖关系
需要明确边界，做到队友死自己不死。

**总结3、4、5：研发规范、自身稳定、容错下游、防御上游。**

#### 6.资源隔离
  进程、线程隔离；集群、机房隔离；读写隔离、动静隔离
  **举例**
 当业务依赖的下游服务出故障时不影响自身的核心功能或服务。例如：用户登录账号对上层业务提供的鉴权和查询服务即核心服务，这些服务的QPS非常高，业务方对它们的可用性要求也很高，别说是服务故障，就连任何一点抖动都是不能接受的。对此我们先从整体架构上把服务拆分，其次在服务内对下游依赖做资源隔离，都尽可能的缩小故障发生时的影响范围。
#### 7.慢查询的问题
 **解决方法**：

* 将查询分成实时查询、近实时查询和离线查询。实时查询可穿透数据库，其它的不走数据库，可以用Elasticsearch来实现一个查询中心，处理近实时查询和离线查询。
* 读写分离。写走主库，读走从库。
* 索引优化。索引过多会影响数据库写性能。索引不够查询会慢。DBA建议一个数据表的索引数不超过4个，超过4个说明表结构不合理，需要考虑重新设计。
* 不允许出现大表。MySQL数据库的一张数据表当数据量达到千万级，效率开始急剧下降。


#### 8.废弃逻辑和临时代码
*   梳理每个接口的调用情况，对于没有调用量的接口，确认不再使用后及时下线。
*   code review保证每段逻辑都明白其含义，弄清楚是否是历史逻辑或者临时逻辑


### 五、持续跟进，定期检查checklist

 大分类 | 具体项
---- | ---|
基础组件 | redis、mysql、nsq、日志(elk)
依赖内外部系统 |  超时时间、超时次数、幂等性、挂掉后是否有熔断
被依赖的内外部系统|超时时间、超时次数、幂等性、是否限流
核心api|qps、cup、内存使用率

> reference:
* [meituan-account](https://tech.meituan.com/dp_account_high_avaliable_road.html)
* [meituan-pay](https://tech.meituan.com/Trade-High-Availability-in-Action.html)
* [meituan-zhanlang](http://itindex.net/detail/58097-%E6%88%98%E7%8B%BC-%E9%A1%B9%E7%9B%AE-%E7%BE%8E%E5%9B%A2)
