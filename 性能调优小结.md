
## 本节大纲
* [一、api代码](#1)
* [二、mysql](#2)
* [三、redis](#3)
* [四、小结](#4)
## 前言
性能调优，包括 api代码 、mysql、redis方面。

## <span id="1">一、api代码</span>

* 抵御上游：限流
* 容错下游：熔断、降级，设置合理重试次数和超时时间
* 规范自己：
   - codeReview明白每一段代码逻辑，弄清楚是历史逻辑还是临时逻辑
   - 梳理每一个接口，不用的接口及时下线
   - 代码hui
*  内存、cpu暴增，使用pprof+火焰图
 ~~~
 ### 问题现象描述
top命令查询服务器负载达到大于5，cpu使用率达到接近100%
### 排查分析思路
* 1.监控系统未发现流量峰值出现
* 2.df-l :磁盘使用率未超出正常范围  
* 3.free :内存使用率未超出正常范围并且还有空闲
* 4.free -m :内存使用量和交换区使用量未发现异常
* 5.磁盘 read io 增大，估计某个goroutine一直占着cpu,进入死循环
 ~~~
* slice删除、反转、筛选、去重;

~~~go
func removeByIdx(s []int, i int) []int {
	if i >= len(s) {
		return s
	}
	copy(s[i:], s[i+1:])
	return s[:len(s)-1]
}

func main() {
	s := []int{1, 2, 3, 4, 5}
	fmt.Println(removeByIdx(s, 2)) //[1 2 4 5]
}
~~~
* 减少new对象的分配，尽量使用临时对象,因为gc会有延迟;
* map、slice初始化容量大小,并发情况下，map需要加锁
~~~go
m := make(map[string]string, 10)
s := make([]string, 0, 10) // 注意：第二个参数是初始大小，第三个参数才是容量
~~~
* 分页数据全量与水位增量的拉取
* 使用byte.Buffer，尽量不拼接字符串
* 并发问题，channel适合数据流动；mutex适合静态，侧重给goroutine访问权限，比如 更新某个状态，更新cache
* 异步化操作，比如 上传打点、上传文件等
* for 循环里面不用使用time.After，因此这样每次都会申请内存，应该在for外面定义变量
* 使用Json-iterator解析json
* ZAP日志pkg不支持按天维度切割日志，选择使用corn+rollingwriter 进行定时拆分


## <span id="2">二、mysql</span>
* 慢查询 不能使用select*，遇到 between > < or in 放在查询条件最后，不影响其它索引
* like查询数据量大的时候使用 搜索引擎处理，比如：es
* join 查询用小表join大表，join字段上加上索引或者分两个sql查询
* 分页数据量大的时候，不要使用limit offset cnt,使用主键索引做条件
~~~
-- 性能差
select * from t limit 10000,50， 

-- 使用主键 索引，b+树 二分查找快
selec id,name,age from t where id >=(select id from t limit 10000,1) limit 50

~~~
* 索引创建注意点：
   - 1.查询条件字段要么单列普通索引要么多列联合索引，注意最左匹配原则 
   - 2.查询的字段加上索引，避免二次查询，减少io(次方案尽量少用)
   - 3.区分度高的建立索引，区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，主键索引的区分度是1，用户 性别字段可能在大数据面前区分度就是0
* 数据异构：多个数据源聚合(mq)，然后放在cache
* 分库、分表、es搜索
* 能批处理，就不要单个执行，避免锁表
* explain分析

## <span id="3">三、redis</span>

* key/value 命名规范：
  - key:可读性(业务:表:id)；简洁性(不能太长)
  - value:避免大key;根据业务场景选择合适对象存储，权衡性能和内存，比如 ziplist的使用
  - kv:合理设置ttl
* redis 设置合理超时，避免连接数占满
* 批量处理，使用管道技术pipeline
* 合理ttl,根据场景，选择合适缓存策略(把redis分表当cache和db使用)
* 短key,禁用keys *
* 查询量大时，优先使用scan/hscan/scan/sscan替代；量小时使用 hgetall、sismember、zrange
* 删除时，量大的时，使用 hscan+hdel、sscan+srem、szcan+zrem
* 存储量小的话，尽量使用hash,不用户kv,因为hash底层压缩链表，占内存少。1百万占70M vs 15M


## <span id="4">总结</span>
* 遇到项目，首先分享业务与功能，实际产出数据与逻辑，然后再写代码
* 业务中常用到的算法 递归、二分查找、排序
* 了解一下底层知识，一方面写出高性能代码，另一方面排查问题思路
* 链路监控必能少，尤其是mysql、redis 使用情况
* 保证核心api 正常运行，做好降级

